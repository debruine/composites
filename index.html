<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>The Composite Method Produces High False Positive Rates</title>

<script src="index_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="index_files/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="index_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="index_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="index_files/navigation-1.1/tabsets.js"></script>
<script src="index_files/navigation-1.1/codefolding.js"></script>
<link href="index_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="index_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>


<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">The Composite Method Produces High False Positive Rates</h1>
<h4 class="author">Lisa DeBruine</h4>
<address class="author_afil">
1<br><a class="author_email" href="mailto:#"><a href="mailto:lisa.debruine@glasgow.ac.uk" class="email">lisa.debruine@glasgow.ac.uk</a></a>
</address>
<div class="abstract">
<p class="abstract">Abstract</p>
<p>In this paper I will explain a serious caveat to research using composite faces to conclude something about group differences from judgements of a single pair or a small number of pairs of composites. Using data simulation, I will demonstrate how this method inevitably leads to a high false positive rate, and how this problem is made worse by using a larger number of raters. I conclude by suggesting alternative methods for assessing the relationship between face morphology and individual traits.</p>
</div>

</div>


<p>A recent paper by <span class="citation">Alper et al. (2021)</span> used faces from the Faceaurus database <span class="citation">(Holtzman, 2011)</span>. “Holtzman (2011) standardized the assessment scores, computed average scores of self- and peer-reports, and ranked the face images based on the resulting scores. Then, prototypes for each of the personality dimensions were created by digitally combining 10 faces with the highest, and 10 faces with the lowest scores on the personality trait in question (Holtzman, 2011).” This was done separately for male and female faces.</p>
<p>With 105 observers, Holtzman found that the ability to detect the composite higher in a dark triad trait was greater than chance for all three traits for each sex. However, since scores on the three dark triad traits are positively correlated, the three pairs of composite faces are not independent. Indeed, Holtzman states that five individuals were in all three low composites for the male faces, while the overlap was less extreme in other cases. Alper and colleagues replicated these findings in three studies with Ns of 160, 318, and 402, the larger two of which were pre-registered.</p>
<p>While I commend both Holtzman and Alper, Bayrak, and Yilmaz for their transparency, data sharing, and material sharing, I argue that the original test has an effective N of 2, not 105, and that further replications using these images, such as those done by Alper, Bayrak, and Yilmaz, regardless of number of observers or preregistered status, lend no further weight of evidence to the assertion that dark triad traits are visible in physical appearance.</p>
<div id="analogy" class="section level2">
<h2>Analogy</h2>
<p>To explain why, I’ll start with an analogy that has nothing to do with faces (bear with me). Imagine a researcher predicts that women born on odd days are taller than women born on even days. Ridiculous, right? So let’s simulate some data assuming that isn’t true. The code below samples 20 women from a population with a mean height of 162 cm and a standard deviation of 7 (values for women in Scotland). Half are born on odd days and half on even days.</p>
<pre class="r"><code>set.seed(42)

stim_n &lt;- 10
height_m &lt;- 162
height_sd &lt;- 7

odd &lt;- rnorm(stim_n, height_m, height_sd)
even &lt;- rnorm(stim_n, height_m, height_sd)

t &lt;- t.test(odd, even, alternative = &quot;greater&quot;)</code></pre>
<pre class="r"><code>e &lt;- effectsize::cohens_d(odd, even)
stats &lt;- glue::glue(&quot;$t_{{{apa_num(t$parameter)}}} = {apa_num(t$statistic)}, p = {apa_p(t$p.value)}, d = {apa_num(e$Cohens_d)}$&quot;)</code></pre>
<p>A t-test shows no significant difference (<span class="math inline">\(t_{13.42} = 1.23, p = .121, d = 0.55\)</span>), which is unsurprising. We simulated the data from the same distribution, so we know for sure there is no real difference here. Now we’re going to average the height of the women with odd and even birthdays. So if we create a full-body composite of women born on odd days, she would be 165.8 cm tall, and a composite of women born on even days would be 160.9 cm tall.</p>
<p>If we ask observers to look at these two composites, side-by-side, and judge which one looks taller, what do you imagine would happen? It’s likely that nearly all of them would judge the odd-birthday composite as taller. But let’s say that observers have to judge the composites independently, and they are pretty bad with height estimation, so their estimates for each composite have error with a standard deviation of 10 cm. We then compare their estimates for the odd-birthday composite with the estimate for the even-birthday composite in a paired-samples t-test.</p>
<pre class="r"><code>set.seed(8675309)

obs_n &lt;- 25 # number of observers
error_sd &lt;- 10 # observer error

# add the error to the composite mean heights
odd_estimates  &lt;- mean(odd)  + rnorm(obs_n, 0, error_sd)
even_estimates &lt;- mean(even) + rnorm(obs_n, 0, error_sd)

t &lt;- t.test(odd_estimates, even_estimates, alternative = &quot;greater&quot;)</code></pre>
<p>Now the women with odd birthdays are significantly taller than the women with even birthdays (<span class="math inline">\(t_{43.06} = 2.41, p = .010, d = 0.55\)</span>)!</p>
<p>And if you increase the number of raters, you can virtually guarantee significant results, even for tiny differences or traits that people are very bad at estimating.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-6"></span>
<img src="index_files/figure-html/unnamed-chunk-6-1.png" alt="As you increase the number of raters up to 500, the power to detect a difference with a Cohen's d as small as 0.2 increases to 95%." width="100%" />
<p class="caption">
Figure 1: As you increase the number of raters up to 500, the power to detect a difference with a Cohen’s d as small as 0.2 increases to 95%.
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="index_files/figure-html/unnamed-chunk-8-1.png" alt="Simulated data showing the distribution of effect sizes for the difference between pairs of composite faces sampled from the same distribution (i.e., no real effect). Points show the median unsigned effect size." width="100%" />
<p class="caption">
Figure 2: Simulated data showing the distribution of effect sizes for the difference between pairs of composite faces sampled from the same distribution (i.e., no real effect). Points show the median unsigned effect size.
</p>
</div>
</div>
<div id="simulation" class="section level2">
<h2>Simulation</h2>
<p>Now we can return to the Holtzman example.</p>
<p>Simulate 100 datasets of self and peer dark triad scores with the same structure as the original study. Each simulated dataset will have 48 women and 33 men whose Machiavellian, narcissism, NPD, and psychopathy scores are correlated in the same way as the original study.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="index_files/figure-html/unnamed-chunk-11-1.png" alt="Correlation structure of the original data and simulations." width="100%" />
<p class="caption">
Figure 3: Correlation structure of the original data and simulations.
</p>
</div>
<p>Next, calculate the average dark triad score for each subject and create a “dark triad face morphology” score to represent the extent to which each subject’s face is perceived as high in dark triad traits. Importantly, in this simulation, the face morphology score will have <em>zero</em> correlation to the average dark triad score.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-13"></span>
<img src="index_files/figure-html/unnamed-chunk-13-1.png" alt="There is no systematic relationship between dark triad trait scores and facial morphology across replicates." width="100%" />
<p class="caption">
Figure 4: There is no systematic relationship between dark triad trait scores and facial morphology across replicates.
</p>
</div>
<p>Now pick the 10 images with the highest and lowest scores for each trait for each gender and create composites of these images. Since the trait scores are positively correlated, there is likely to be a lot of overlap in the images that go into the three high and three low composites for each gender.</p>
<p>Even though the face attributes that are perceived as higher in dark triad traits are totally unrelated to the scores, the composites will still differ in these traits, some more than others, and half the time in the predicted direction.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-15"></span>
<img src="index_files/figure-html/unnamed-chunk-15-1.png" alt="Differences in average dark triad face morphology between the high and low dark triad trait groups for the first replicate." width="100%" />
<p class="caption">
Figure 5: Differences in average dark triad face morphology between the high and low dark triad trait groups for the first replicate.
</p>
</div>
<p>Following Holtzman, we will simulate raters for each replicate giving -5 to +5 ratings for which face looks more Machiavellian, narcissistic, or psychopathic. <!--Each pairing will be rated twice by each rater.--></p>
<p>By chance alone, some of the values will be significant in the predicted direction.</p>
<caption>
<span id="tab:unnamed-chunk-19">Table 1: </span>
</caption>
<div custom-style="Table Caption">
**
</div>
<table>
<thead>
<tr class="header">
<th align="left">gender</th>
<th align="left">trait</th>
<th align="left">estimate</th>
<th align="left">statistic</th>
<th align="left">p.value</th>
<th align="left">sig</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">female</td>
<td align="left">mach</td>
<td align="left">-0.27</td>
<td align="left">-1.82</td>
<td align="left">0.96</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">female</td>
<td align="left">narc</td>
<td align="left">0.22</td>
<td align="left">1.52</td>
<td align="left">0.07</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">female</td>
<td align="left">psycho</td>
<td align="left">-0.20</td>
<td align="left">-1.32</td>
<td align="left">0.90</td>
<td align="left">FALSE</td>
</tr>
<tr class="even">
<td align="left">male</td>
<td align="left">mach</td>
<td align="left">-0.14</td>
<td align="left">-0.98</td>
<td align="left">0.84</td>
<td align="left">FALSE</td>
</tr>
<tr class="odd">
<td align="left">male</td>
<td align="left">narc</td>
<td align="left">0.47</td>
<td align="left">3.06</td>
<td align="left">0.00</td>
<td align="left">TRUE</td>
</tr>
<tr class="even">
<td align="left">male</td>
<td align="left">psycho</td>
<td align="left">0.82</td>
<td align="left">5.27</td>
<td align="left">0.00</td>
<td align="left">TRUE</td>
</tr>
</tbody>
</table>
<p><img src="index_files/figure-html/unnamed-chunk-20-1.png" width="100%" /></p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-21"></span>
<img src="index_files/figure-html/unnamed-chunk-21-1.png" alt="Distribution of replicates with 0 to 6 significant results in the predicted direction (one-tailed one-sample t-tests with alpha = 0.05)." width="100%" />
<p class="caption">
Figure 6: Distribution of replicates with 0 to 6 significant results in the predicted direction (one-tailed one-sample t-tests with alpha = 0.05).
</p>
</div>
<p>People tend to show high agreement on stereotypical social perceptions from the physical appearance of faces, even when physical appearance is not meaningfully associated with the traits being judged <span class="citation">(Jones et al., 2021; Todorov et al., 2008; Zebrowitz &amp; Montepare, 2008)</span>. We can be sure that by chance alone, our two composites will be at least slightly different on any measure, even if they are drawn from identical populations.</p>
<p>The smaller the number of stimuli that go into each composite, the larger the mean (unsigned) size of this difference. With only 10 stimuli per composite (like the Facesaurus composites), the mean unsigned effect size of the difference between composites from populations with no real difference is 0.35 (in units of SD of the original trait distribution). If our observers are accurate enough at perceiving this difference, or we run a very large number of observers, we are virtually guaranteed to find significant results every time. Additionally, there is a 50% chance that these results will be in the predicted direction, and this direction will be replicable across different samples of observers for the same image set.</p>
</div>
<div id="implications-for-face-research" class="section level2">
<h2>Implications for Face Research</h2>
<p>So what does this mean for studies of the link between personality traits and facial appearance? The analogy with birth date and height holds. As long as there are facial morphologies that are even slightly consistently associated with the <em>perception</em> of a trait, then composites will not be identical in that morphology. Thus, even if that morphology is totally unassociated with the trait as measured by, e.g., personality scales or peer report (which is often the case), using the composite rating method will inflate the false positive rate for concluding a difference.</p>
<p>The smaller the number of stimuli that go into each composite, the greater the chance that they will be visibly different in morphology related to the judgement of interest, just by chance alone. The larger the number of observers or the better observers are at detecting small differences in this morphology, the more likely that “detection” will be significantly above chance. Repeating this with a new set of observers does not increase the amount of evidence you have for the association between the face morphology and the measured trait. You’ve only measured it once in one population of faces. If observers are your unit of analyses, you are making conclusions about whether the population of observers can detect the difference between your stimuli, you cannot generalise this to new stimulus sets.</p>
</div>
<div id="alternative-methods" class="section level2">
<h2>Alternative methods</h2>
<p>So how should researchers test for differences in facial appearance between groups?</p>
<div id="assessment-of-individual-faces" class="section level3">
<h3>Assessment of individual faces</h3>
<p>Assessment of individual face images, combined with mixed effects models <span class="citation">(L. M. DeBruine &amp; Barr, 2021)</span>, can allow you to simultaneously account for variance in both observers and stimuli, avoiding the inflated false positives of the composite method (or aggregating ratings). People often use the composite method when they have too many images for any one observer to rate, but cross-classified mixed models can analyse data from counterbalanced trials or randomised subset allocation.</p>
<p>Another reason to use the composite rating method is when you are not ethically permitted to use individual faces in research, but are ethically permitted to use non-identifiable composite images. In this case, you can generate a large number of random composite pairs to construct the chance distribution. The equivalent to a p-value for this method is the proportion of the randomly paired composites that your target pair has a more extreme result than. While this method is too tedious to use when constructing composite faces manually, scripting allows you to automate such a task.</p>
<pre class="r"><code>set.seed(8675309) # for reproducibility

# load 20 faces
f &lt;- load_stim_canada(&quot;f&quot;) |&gt; resize(0.5)

# set to the number of random pairs you want
n_pairs &lt;- 5

# repeat this code n_pairs times
pairs &lt;- lapply(1:n_pairs, function (i) {
  # sample a random 10:10 split
  rand1 &lt;- sample(names(f), 10)
  rand2 &lt;- setdiff(names(f), rand1)
  
  # create composite images
  comp1 &lt;- avg(f[rand1])
  comp2 &lt;- avg(f[rand2])
  
  # save images with paired names
  nm1 &lt;- paste0(&quot;img_&quot;, i, &quot;_a&quot;)
  nm2 &lt;- paste0(&quot;img_&quot;, i, &quot;_b&quot;)
  write_stim(comp1, dir = &quot;images/composites&quot;, names = nm1)
  write_stim(comp2, dir = &quot;images/composites&quot;, names = nm2)
})</code></pre>
<div class="figure"><span style="display:block;" id="fig:rand-pair"></span>
<img src="index_files/figure-html/rand-pair-1.png" alt="Five random pairs of composites from a sample of 20 faces (10 in each composite). Can you spot any differences?" width="100%" />
<p class="caption">
Figure 7: Five random pairs of composites from a sample of 20 faces (10 in each composite). Can you spot any differences?
</p>
</div>
</div>
<div id="open-resources" class="section level3">
<h3>Open Resources</h3>
<p>All image sets used in this tutorial are available on a CC-BY license at <a href="https://figshare.com/search?q=webmorph%20psychomorph">figshare</a> and all software is available open source. The code to reproduce this paper can be found at <a href="https://github.com/debruine/composites" class="uri">https://github.com/debruine/composites</a>.</p>
<p>We used R <span class="citation">(Version 4.3.1; R Core Team, 2023)</span> and the R-packages <em>broom</em> <span class="citation">(Version 1.0.5; Robinson et al., 2023)</span>, <em>dplyr</em> <span class="citation">(Version 1.1.2; Wickham, François, et al., 2023)</span>, <em>faux</em> <span class="citation">(Version 1.2.1; L. DeBruine, 2023)</span>, <em>ggplot2</em> <span class="citation">(Version 3.4.2; Wickham, 2016)</span>, <em>glue</em> <span class="citation">(Version 1.6.2; Hester &amp; Bryan, 2022)</span>, <em>kableExtra</em> <span class="citation">(Version 1.3.4; Zhu, 2021)</span>, <em>papaja</em> <span class="citation">(Version 0.1.1; Aust &amp; Barth, 2022)</span>, <em>purrr</em> <span class="citation">(Version 1.0.1; Wickham &amp; Henry, 2023)</span>, <em>tidyr</em> <span class="citation">(Version 1.3.0; Wickham, Vaughan, et al., 2023)</span>, <em>tinylabels</em> <span class="citation">(Version 0.2.3; Barth, 2022)</span>, <em>webmorphR</em> <span class="citation">(Version 0.1.1; L. DeBruine, 2022; L. DeBruine &amp; Jones, 2017)</span>, and <em>webmorphR.stim</em> <span class="citation">(Version 0.0.0.9002; L. DeBruine &amp; Jones, 2017)</span> to produce this manuscript.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" custom-style="Bibliography" line-spacing="2">
<div id="ref-alper2021all" class="csl-entry">
Alper, S., Bayrak, F., &amp; Yilmaz, O. (2021). All the dark triad and some of the big five traits are visible in the face. <em>Personality and Individual Differences</em>, <em>168</em>, 110350. https://doi.org/<a href="https://doi.org/10.1016/j.paid.2020.110350">https://doi.org/10.1016/j.paid.2020.110350</a>
</div>
<div id="ref-R-papaja" class="csl-entry">
Aust, F., &amp; Barth, M. (2022). <em><span class="nocase">papaja</span>: <span>Prepare</span> reproducible <span>APA</span> journal articles with <span>R Markdown</span></em>. <a href="https://github.com/crsh/papaja">https://github.com/crsh/papaja</a>
</div>
<div id="ref-R-tinylabels" class="csl-entry">
Barth, M. (2022). <em><span class="nocase">tinylabels</span>: Lightweight variable labels</em>. <a href="https://cran.r-project.org/package=tinylabels">https://cran.r-project.org/package=tinylabels</a>
</div>
<div id="ref-R-webmorphR" class="csl-entry">
DeBruine, L. (2022). <em>webmorphR: Reproducible stimuli</em>. <a href="https://CRAN.R-project.org/package=webmorphR">https://CRAN.R-project.org/package=webmorphR</a>
</div>
<div id="ref-R-faux" class="csl-entry">
DeBruine, L. (2023). <em>Faux: Simulation for factorial designs</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.2669586">https://doi.org/10.5281/zenodo.2669586</a>
</div>
<div id="ref-debruine2021understanding" class="csl-entry">
DeBruine, L. M., &amp; Barr, D. J. (2021). Understanding mixed-effects models through data simulation. <em>Advances in Methods and Practices in Psychological Science</em>, <em>4</em>(1), 2515245920965119.
</div>
<div id="ref-R-webmorphR.stim" class="csl-entry">
DeBruine, L., &amp; Jones, B. (2017). <em>Face research lab london set</em>. figshare. <a href="https://doi.org/10.6084/m9.figshare.5047666.v5">https://doi.org/10.6084/m9.figshare.5047666.v5</a>
</div>
<div id="ref-R-glue" class="csl-entry">
Hester, J., &amp; Bryan, J. (2022). <em>Glue: Interpreted string literals</em>. <a href="https://CRAN.R-project.org/package=glue">https://CRAN.R-project.org/package=glue</a>
</div>
<div id="ref-holtzman2011facing" class="csl-entry">
Holtzman, N. S. (2011). Facing a psychopath: Detecting the dark triad from emotionally-neutral faces, using prototypes from the personality faceaurus. <em>Journal of Research in Personality</em>, <em>45</em>(6), 648–654.
</div>
<div id="ref-jones2021world" class="csl-entry">
Jones, B. C., DeBruine, L. M., Flake, J. K., Liuzza, M. T., Antfolk, J., Arinze, N. C., Ndukaihe, I. L. G., Bloxsom, N. G., Lewis, S. C., Foroni, F., et al. (2021). To which world regions does the valence–dominance model of social perception apply? <em>Nature Human Behaviour</em>, <em>5</em>(1), 159–169.
</div>
<div id="ref-R-base" class="csl-entry">
R Core Team. (2023). <em>R: A language and environment for statistical computing</em>. R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>
</div>
<div id="ref-R-broom" class="csl-entry">
Robinson, D., Hayes, A., &amp; Couch, S. (2023). <em>Broom: Convert statistical objects into tidy tibbles</em>. <a href="https://CRAN.R-project.org/package=broom">https://CRAN.R-project.org/package=broom</a>
</div>
<div id="ref-todorov2008understanding" class="csl-entry">
Todorov, A., Said, C. P., Engell, A. D., &amp; Oosterhof, N. N. (2008). Understanding evaluation of faces on social dimensions. <em>Trends in Cognitive Sciences</em>, <em>12</em>(12), 455–460.
</div>
<div id="ref-R-ggplot2" class="csl-entry">
Wickham, H. (2016). <em>ggplot2: Elegant graphics for data analysis</em>. Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>
</div>
<div id="ref-R-dplyr" class="csl-entry">
Wickham, H., François, R., Henry, L., Müller, K., &amp; Vaughan, D. (2023). <em>Dplyr: A grammar of data manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>
</div>
<div id="ref-R-purrr" class="csl-entry">
Wickham, H., &amp; Henry, L. (2023). <em>Purrr: Functional programming tools</em>. <a href="https://CRAN.R-project.org/package=purrr">https://CRAN.R-project.org/package=purrr</a>
</div>
<div id="ref-R-tidyr" class="csl-entry">
Wickham, H., Vaughan, D., &amp; Girlich, M. (2023). <em>Tidyr: Tidy messy data</em>. <a href="https://CRAN.R-project.org/package=tidyr">https://CRAN.R-project.org/package=tidyr</a>
</div>
<div id="ref-zebrowitz2008social" class="csl-entry">
Zebrowitz, L. A., &amp; Montepare, J. M. (2008). Social psychological face perception: Why appearance matters. <em>Social and Personality Psychology Compass</em>, <em>2</em>(3), 1497–1517.
</div>
<div id="ref-R-kableExtra" class="csl-entry">
Zhu, H. (2021). <em>kableExtra: Construct complex table with ’kable’ and pipe syntax</em>. <a href="https://CRAN.R-project.org/package=kableExtra">https://CRAN.R-project.org/package=kableExtra</a>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
